{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"XDG_CACHE_HOME\"] = \"/home/olab/tomerronen1/xdg_cache/\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/mbart-large-50-one-to-many-mmt\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/mbart-large-50-one-to-many-mmt\", src_lang=\"en_XX\")\n",
    "model.orig_generate = model.generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# article_en = [\"The head of the United Nations says there is no military solution in Syria\", \"lol\"]\n",
    "\n",
    "# model_inputs = tokenizer(article_en, return_tensors=\"pt\", padding=True)\n",
    "# generation_params = {\"num_beams\": 5, \"length_penalty\": 1.0, \"num_return_sequences\": 5}\n",
    "\n",
    "# # translate from English to Hindi\n",
    "# generated_tokens = model.generate(\n",
    "#     **model_inputs,\n",
    "#     forced_bos_token_id=tokenizer.lang_code_to_id[\"hi_IN\"],\n",
    "#     **generation_params\n",
    "# )\n",
    "# # print(tokenizer.batch_decode(generated_tokens, skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from transformers import Seq2SeqTrainer, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments\n",
    "dataset = Dataset.from_dict({\"text\": [\"This is a setnence.\", \"How many woods are there in the woods?\"]})\n",
    "dataset = dataset.map(tokenizer, input_columns=\"text\")\n",
    "if not \"forced_bos_token_id\" in dataset.column_names:\n",
    "    dataset = dataset.add_column(\"forced_bos_token_id\", [tokenizer.lang_code_to_id[\"hi_IN\"]] * len(dataset))\n",
    "trainer_args = Seq2SeqTrainingArguments(output_dir='/tmp/lol', predict_with_generate=True)\n",
    "trainer = Seq2SeqTrainer(model, args=trainer_args, data_collator=DataCollatorForSeq2Seq(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "generation_kwargs = dict(forced_bos_token_id=tokenizer.lang_code_to_id[\"hi_IN\"], length_penalty=1.0, num_beams=2, num_return_sequences=2)\n",
    "def custom_generate(*args, **kwargs):\n",
    "    num_beams = 2\n",
    "    kwargs = {**kwargs, **generation_kwargs}\n",
    "    generated_tokens = model.orig_generate(*args, **kwargs)\n",
    "    generated_tokens = torch.hstack([generated_tokens, -100 * torch.ones((generated_tokens.shape[0], 1), dtype=int)])\n",
    "    batch_size = generated_tokens.shape[0] // num_beams\n",
    "    generated_tokens = generated_tokens.reshape(batch_size, -1)\n",
    "    return generated_tokens\n",
    "model.generate = custom_generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_preds = trainer.predict(dataset).predictions\n",
    "concatenated_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def flatten(nested_list: list[list]) -> list:\n",
    "    return [item for sublist in nested_list for item in sublist]\n",
    "\n",
    "num_beams = 2\n",
    "preds = []\n",
    "for pred in concatenated_preds:\n",
    "    different_beams = np.array_split(pred, np.flatnonzero(pred == -100) + 1)\n",
    "    different_beams = different_beams[:-1]  # last one is padding\n",
    "    for beam_pred in different_beams:\n",
    "        beam_pred = beam_pred[beam_pred != -100]\n",
    "        preds.append(beam_pred)\n",
    "\n",
    "tokenizer.batch_decode(preds, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.data_collator(dataset.to_list())\n",
    "# trainer.data_collator(dataset.to_dict(orient=\"list\"))\n",
    "batch = trainer.data_collator(dataset.to_pandas()[[\"input_ids\", \"attention_mask\"]].to_dict(orient=\"records\"))\n",
    "# trainer.data_collator([dataset[i] for i in range(len(dataset))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = trainer.model.generate(**batch)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = trainer.predict(dataset)\n",
    "preds.predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_en = \"The head of the United Nations says there is no military solution in Syria\"\n",
    "\n",
    "model_inputs = tokenizer(article_en, return_tensors=\"pt\")\n",
    "generation_params = {\"num_beams\": 5, \"length_penalty\": 1.0}\n",
    "\n",
    "# translate from English to Hindi\n",
    "generated_tokens = model.generate(\n",
    "    **model_inputs,\n",
    "    forced_bos_token_id=tokenizer.lang_code_to_id[\"hi_IN\"],\n",
    "    **generation_params\n",
    ")\n",
    "print(tokenizer.batch_decode(generated_tokens, skip_special_tokens=True))\n",
    "# => 'संयुक्त राष्ट्र के नेता कहते हैं कि सीरिया में कोई सैन्य समाधान नहीं है'\n",
    "\n",
    "# translate from English to Chinese\n",
    "generated_tokens = model.generate(\n",
    "    **model_inputs,\n",
    "    forced_bos_token_id=tokenizer.lang_code_to_id[\"zh_CN\"],\n",
    "    **generation_params\n",
    ")\n",
    "print(tokenizer.batch_decode(generated_tokens, skip_special_tokens=True))\n",
    "# => '联合国首脑说,叙利亚没有军事解决办法'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_many_to_en = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/mbart-large-50-many-to-one-mmt\")\n",
    "tokenizer_many_to_en = AutoTokenizer.from_pretrained(\"facebook/mbart-large-50-many-to-one-mmt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_hi = \"संयुक्त राष्ट्र के प्रमुख का कहना है कि सीरिया में कोई सैन्य समाधान नहीं है\"\n",
    "article_ar = \"الأمين العام للأمم المتحدة يقول إنه لا يوجد حل عسكري في سوريا.\"\n",
    "\n",
    "# translate Hindi to English\n",
    "tokenizer_many_to_en.src_lang = \"hi_IN\"\n",
    "encoded_hi = tokenizer(article_hi, return_tensors=\"pt\")\n",
    "generated_tokens = model_many_to_en.generate(**encoded_hi, **generation_params)\n",
    "print(tokenizer_many_to_en.batch_decode(generated_tokens, skip_special_tokens=True))\n",
    "# => \"The head of the UN says there is no military solution in Syria.\"\n",
    "\n",
    "# translate Arabic to English\n",
    "tokenizer_many_to_en.src_lang = \"ar_AR\"\n",
    "encoded_ar = tokenizer_many_to_en(article_ar, return_tensors=\"pt\")\n",
    "generated_tokens = model_many_to_en.generate(**encoded_ar, **generation_params)\n",
    "print(tokenizer.batch_decode(generated_tokens, skip_special_tokens=True))\n",
    "# => \"The Secretary-General of the United Nations says there is no military solution in Syria.\"\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('mlskel')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1388c48c1b848a0052718750b16c870cff087208ab0cafaf53720e4cd74eb1e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
