{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"XDG_CACHE_HOME\"] = \"/home/olab/tomerronen1/xdg_cache/\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/mbart-large-50-one-to-many-mmt\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/mbart-large-50-one-to-many-mmt\", src_lang=\"en_XX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.mbart50.tokenization_mbart50_fast import FAIRSEQ_LANGUAGE_CODES\n",
    "LANG_CODE_TO_FAIRSEQ_FORMAT = {long_language_code[:2]: long_language_code for long_language_code in FAIRSEQ_LANGUAGE_CODES}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_en = [\"The head of the United Nations says there is no military solution in Syria\", \"lol\"]\n",
    "\n",
    "num_beams = 2\n",
    "tgt_lang_code = \"he\"\n",
    "max_output_to_input_ratio = 1.2\n",
    "\n",
    "model_inputs = tokenizer(article_en, return_tensors=\"pt\", padding=True)\n",
    "batch_size, input_length = model_inputs[\"input_ids\"].shape\n",
    "\n",
    "forced_bos_token_id = tokenizer.lang_code_to_id[LANG_CODE_TO_FAIRSEQ_FORMAT[tgt_lang_code]]\n",
    "\n",
    "gen_output = model.generate(\n",
    "    **model_inputs,\n",
    "    forced_bos_token_id=forced_bos_token_id,\n",
    "    num_beams=num_beams,\n",
    "    num_return_sequences=num_beams,\n",
    "    max_new_tokens=int(max_output_to_input_ratio * 1.2),\n",
    "    return_dict_in_generate=True,\n",
    "    output_scores=True,\n",
    ")\n",
    "# print(tokenizer.batch_decode(generated_tokens, skip_special_tokens=True))\n",
    "tokenizer.batch_decode(gen_output.sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(nested_list: list[list]) -> list:\n",
    "    return [item for sublist in nested_list for item in sublist]\n",
    "\n",
    "import torch\n",
    "special_tokens = flatten([[toks] if isinstance(toks, str) else toks\n",
    "                          for toks in tokenizer.special_tokens_map.values()])\n",
    "special_token_ids = tokenizer.convert_tokens_to_ids(special_tokens)\n",
    "special_token_ids = torch.tensor(special_token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = gen_output.sequences.view(batch_size, num_beams, -1)\n",
    "tokenizer.convert_ids_to_tokens(tokenizer(\"lol\")[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = gen_output.sequences.view(batch_size, num_beams, -1)\n",
    "sequences = sequences[:, :, 1:]  # drop the eos token that starts generation\n",
    "sequences = [[seq[seq != tokenizer.pad_token_id].tolist() for seq in beam] for beam in sequences]\n",
    "scores = gen_output.sequences_scores.view(batch_size, num_beams).tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "dataset = Dataset.from_dict({\"src_sentence\": [\"מדובר בחתול נאה מאוד\", \"אלליי, איזו מרשתת!\"], \"id\": [\"a\", \"b\"]})\n",
    "# dataset = dataset.map(tokenizer_many_to_en, batched=True, input_columns=[\"src_sentence\"])\n",
    "# tokenizer.batch_decode(model_many_to_en.generate(input_ids=torch.tensor([dataset[1][\"input_ids\"]]),\n",
    "#                           attention_mask=torch.tensor([dataset[1][\"attention_mask\"]])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"XDG_CACHE_HOME\"] = \"/home/olab/tomerronen1/xdg_cache/\"\n",
    "dataset.with_format(columns=[\"src_sentence\"])[[1,0]][\"src_sentence\"][0]\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_of_lists_to_list_of_dicts(d: dict[list]) -> list[dict]:\n",
    "    return [dict(zip(d.keys(), vals)) for vals in zip(*d.values())]\n",
    "\n",
    "\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "collator = DataCollatorForSeq2Seq(tokenizer)\n",
    "dataset = dataset.map(tokenizer, input_columns=\"src_sentence\", batched=True)\n",
    "batch = dataset.with_format(columns=[\"input_ids\", \"attention_mask\"])[[1,0]]\n",
    "batch = dict_of_lists_to_list_of_dicts(batch)\n",
    "collator(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.add_item({\"src_sentence\": \"aaa\", \"id\": \"g\", \"input_ids\": [3,4,4], \"attention_mask\": [1,1,1]})\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from transformers import Seq2SeqTrainer, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments\n",
    "dataset = Dataset.from_dict({\"text\": [\"This is a setnence.\", \"How many woods are there in the woods?\"]})\n",
    "dataset = dataset.map(tokenizer, input_columns=\"text\")\n",
    "if not \"forced_bos_token_id\" in dataset.column_names:\n",
    "    dataset = dataset.add_column(\"forced_bos_token_id\", [tokenizer.lang_code_to_id[\"hi_IN\"]] * len(dataset))\n",
    "trainer_args = Seq2SeqTrainingArguments(output_dir='/tmp/lol', predict_with_generate=True)\n",
    "trainer = Seq2SeqTrainer(model, args=trainer_args, data_collator=DataCollatorForSeq2Seq(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "generation_kwargs = dict(forced_bos_token_id=tokenizer.lang_code_to_id[\"hi_IN\"], length_penalty=1.0, num_beams=2, num_return_sequences=2)\n",
    "def custom_generate(*args, **kwargs):\n",
    "    num_beams = 2\n",
    "    kwargs = {**kwargs, **generation_kwargs}\n",
    "    generated_tokens = model.orig_generate(*args, **kwargs)\n",
    "    generated_tokens = torch.hstack([generated_tokens, -100 * torch.ones((generated_tokens.shape[0], 1), dtype=int)])\n",
    "    batch_size = generated_tokens.shape[0] // num_beams\n",
    "    generated_tokens = generated_tokens.reshape(batch_size, -1)\n",
    "    return generated_tokens\n",
    "model.generate = custom_generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_preds = trainer.predict(dataset).predictions\n",
    "concatenated_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.convert_ids_to_tokens(gen_output[\"sequences\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_many_to_en = AutoTokenizer.from_pretrained(\"facebook/mbart-large-50-many-to-one-mmt\")\n",
    "tokenizer_many_to_en.src_lang = LANG_CODE_TO_FAIRSEQ_FORMAT[\"he\"]\n",
    "tokenizer_many_to_en.convert_ids_to_tokens(tokenizer_many_to_en(\"זהו משפט בעברית.\")[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.repeat([\"a\",\"fff\"], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bert_score\n",
    "from pathlib import Path\n",
    "bertscore_baseline_languages = [path.name for path in (Path(bert_score.__file__).parent / \"rescale_baseline\").iterdir()]\n",
    "bertscore_baseline_languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "str(Path(\"a\")) + \"b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def flatten(nested_list: list[list]) -> list:\n",
    "    return [item for sublist in nested_list for item in sublist]\n",
    "\n",
    "num_beams = 2\n",
    "preds = []\n",
    "for pred in concatenated_preds:\n",
    "    different_beams = np.array_split(pred, np.flatnonzero(pred == -100) + 1)\n",
    "    different_beams = different_beams[:-1]  # last one is padding\n",
    "    for beam_pred in different_beams:\n",
    "        beam_pred = beam_pred[beam_pred != -100]\n",
    "        preds.append(beam_pred)\n",
    "\n",
    "tokenizer.batch_decode(preds, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.data_collator(dataset.to_list())\n",
    "# trainer.data_collator(dataset.to_dict(orient=\"list\"))\n",
    "batch = trainer.data_collator(dataset.to_pandas()[[\"input_ids\", \"attention_mask\"]].to_dict(orient=\"records\"))\n",
    "# trainer.data_collator([dataset[i] for i in range(len(dataset))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = trainer.model.generate(**batch)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = trainer.predict(dataset)\n",
    "preds.predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_en = \"The head of the United Nations says there is no military solution in Syria\"\n",
    "\n",
    "model_inputs = tokenizer(article_en, return_tensors=\"pt\")\n",
    "generation_params = {\"num_beams\": 5, \"length_penalty\": 1.0}\n",
    "\n",
    "# translate from English to Hindi\n",
    "generated_tokens = model.generate(\n",
    "    **model_inputs,\n",
    "    forced_bos_token_id=tokenizer.lang_code_to_id[\"hi_IN\"],\n",
    "    **generation_params\n",
    ")\n",
    "print(tokenizer.batch_decode(generated_tokens, skip_special_tokens=True))\n",
    "# => 'संयुक्त राष्ट्र के नेता कहते हैं कि सीरिया में कोई सैन्य समाधान नहीं है'\n",
    "\n",
    "# translate from English to Chinese\n",
    "generated_tokens = model.generate(\n",
    "    **model_inputs,\n",
    "    forced_bos_token_id=tokenizer.lang_code_to_id[\"zh_CN\"],\n",
    "    **generation_params\n",
    ")\n",
    "print(tokenizer.batch_decode(generated_tokens, skip_special_tokens=True))\n",
    "# => '联合国首脑说,叙利亚没有军事解决办法'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_many_to_en.generate(**tokenizer_many_to_en(\"אני חתול\", return_tensors=\"pt\"), forced_bos_token_id=250004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_many_to_en = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/mbart-large-50-many-to-one-mmt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_many_to_en = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/mbart-large-50-many-to-one-mmt\")\n",
    "tokenizer_many_to_en = AutoTokenizer.from_pretrained(\"facebook/mbart-large-50-many-to-one-mmt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_hi = \"संयुक्त राष्ट्र के प्रमुख का कहना है कि सीरिया में कोई सैन्य समाधान नहीं है\"\n",
    "article_ar = \"الأمين العام للأمم المتحدة يقول إنه لا يوجد حل عسكري في سوريا.\"\n",
    "\n",
    "# translate Hindi to English\n",
    "tokenizer_many_to_en.src_lang = \"hi_IN\"\n",
    "encoded_hi = tokenizer(article_hi, return_tensors=\"pt\")\n",
    "generated_tokens = model_many_to_en.generate(**encoded_hi, **generation_params)\n",
    "print(tokenizer_many_to_en.batch_decode(generated_tokens, skip_special_tokens=True))\n",
    "# => \"The head of the UN says there is no military solution in Syria.\"\n",
    "\n",
    "# translate Arabic to English\n",
    "tokenizer_many_to_en.src_lang = \"ar_AR\"\n",
    "encoded_ar = tokenizer_many_to_en(article_ar, return_tensors=\"pt\")\n",
    "generated_tokens = model_many_to_en.generate(**encoded_ar, **generation_params)\n",
    "print(tokenizer.batch_decode(generated_tokens, skip_special_tokens=True))\n",
    "# => \"The Secretary-General of the United Nations says there is no military solution in Syria.\"\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('mlskel')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1388c48c1b848a0052718750b16c870cff087208ab0cafaf53720e4cd74eb1e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
