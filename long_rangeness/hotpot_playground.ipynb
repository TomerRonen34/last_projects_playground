{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"XDG_CACHE_HOME\"] = \"/home/olab/tomerronen1/xdg_cache\"\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"hotpot_qa\", \"distractor\")\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"validation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"validation\"][0][\"context\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"validation\"][1][\"supporting_facts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ck46/t5-base-hotpot-qa-qg\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"ck46/t5-base-hotpot-qa-qg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qasper = load_dataset(\"tau/sled\", \"hotpotqa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qasper[\"validation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_example(example):\n",
    "    context = []\n",
    "    for title, sentences in zip(example[\"context\"][\"title\"], example[\"context\"][\"sentences\"]):\n",
    "        context.append(title)\n",
    "        context.append(\":\\n\")\n",
    "        context.extend(sentences)\n",
    "        context.append('\\n\\n')\n",
    "    context.pop()\n",
    "    context = ''.join(context) \n",
    "\n",
    "    question = f\"Question:\\n{example['question']}\\n\"\n",
    "    prepared_example = {\"id\": example[\"id\"], \"pid\": example[\"id\"] + \"_0\", \"input\": context,\n",
    "                        \"input_prefix\": question, \"output\": example[\"answer\"]}\n",
    "    return prepared_example\n",
    "\n",
    "\n",
    "# dataset[\"validation\"].select(range(10)).map(prepare_example)[0]\n",
    "prepared_dataset_dict = dataset.map(prepare_example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_dataset_dict.push_to_hub(\"tomer/sled_hotpotqa_distractor\", private=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = dataset[\"train\"][6]\n",
    "\n",
    "context = []\n",
    "for title, sentences in zip(example[\"context\"][\"title\"], example[\"context\"][\"sentences\"]):\n",
    "    context.append(title)\n",
    "    context.append(\":\\n\")\n",
    "    context.extend(sentences)\n",
    "    context.append('\\n\\n')\n",
    "context.pop()\n",
    "context = ''.join(context) \n",
    "\n",
    "question = f\"Question:\\n{example['question']}\\n\"\n",
    "\n",
    "print(question + '\\n' + context)\n",
    "\n",
    "# print(context)\n",
    "# print(question)\n",
    "# print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = tokenizer(text, return_tensors=\"pt\")\n",
    "max_length = tokenizer.model_max_length\n",
    "batch[\"input_ids\"] = batch[\"input_ids\"][:,-max_length:]\n",
    "batch[\"attention_mask\"] = batch[\"attention_mask\"][:,-max_length:]\n",
    "prediction = tokenizer.batch_decode(model.generate(**batch, num_beams=1, max_length=20))[0]\n",
    "print(prediction)\n",
    "print(example[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('mlskel')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1388c48c1b848a0052718750b16c870cff087208ab0cafaf53720e4cd74eb1e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
